{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein Generative Adversarial Network with Gradient Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WGAN-GP (which stands for Wasserstein Generative Adversarial Network with Gradient Penalty) improves the architecture of a WGAN (designed to counter training related issues of the basic GAN) by ensuring the critics is 1-Lipschitz without using weight clipping (which impacts the critic's ability to learn). There are 3 main changes, the WGAN-GP critic:\n",
    "- Includes a gradient penalty term in the critic loss function\n",
    "- Does not clip its weights\n",
    "- Does not use bacth normalization layers\n",
    "\n",
    "Let's build an WGAN-GP \"from scratch\" to have a better understanding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand Made WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 22:10:03.616401: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-27 22:10:03.621548: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 22:10:03.685502: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-27 22:10:03.685558: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-27 22:10:03.687425: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-27 22:10:03.696973: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 22:10:03.697960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-27 22:10:05.120124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Flatten, Dense, Reshape, UpSampling2D, Activation, BatchNormalization, Dropout, Conv2DTranspose, Layer, Lambda\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# Clear TensorFlow session\n",
    "K.clear_session()\n",
    "\n",
    "# Disable eager execution\n",
    "# from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()\n",
    "\n",
    "# Tensorflow debugging\n",
    "# tf.debugging.enable_check_numerics()\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic():\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim, critic_n_layers, critic_conv_filters, critic_conv_kernel_sizes, critic_conv_strides,\n",
    "                 critic_activation,\n",
    "                 critic_batch_norm_momentum, critic_dropout_rate):\n",
    "        self.input_dim = input_dim\n",
    "        self.critic_n_layers = critic_n_layers\n",
    "        self.critic_conv_filters = critic_conv_filters\n",
    "        self.critic_conv_kernel_sizes = critic_conv_kernel_sizes\n",
    "        self.critic_conv_strides = critic_conv_strides\n",
    "        self.critic_activation = critic_activation\n",
    "        self.critic_batch_norm_momentum = critic_batch_norm_momentum\n",
    "        self.critic_dropout_rate = critic_dropout_rate\n",
    "        self.weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "        self.input = Input(shape=self.input_dim, name=\"critic_input\")\n",
    "        \n",
    "        x = self.input\n",
    "        for i in range(self.critic_n_layers):\n",
    "            x = Conv2D(filters=self.critic_conv_filters[i],\n",
    "                       kernel_size=self.critic_conv_kernel_sizes[i],\n",
    "                       strides=self.critic_conv_kernel_sizes[i],\n",
    "                       padding=\"same\",\n",
    "                       name=\"critic_conv_\" + str(i))(x)\n",
    "            \n",
    "            if self.critic_batch_norm_momentum and i > 0:\n",
    "                x = BatchNormalization(momentum=self.critic_batch_norm_momentum)(x)\n",
    "\n",
    "            x = Activation(activation=self.critic_activation, name=\"critic_activation_\" + str(i))(x)\n",
    "\n",
    "            if self.critic_dropout_rate:\n",
    "                x = Dropout(rate=self.critic_dropout_rate)(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        self.output = Dense(1, activation=None, kernel_initializer=self.weight_init, name=\"critic_output\")(x)\n",
    "\n",
    "        self.model = Model(self.input, self.output, name=\"critic\")\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "\n",
    "    def __init__(self,\n",
    "                 latent_dim, generator_initial_dense_layer_size, generator_n_layers, generator_upsamplings, generator_conv_filters, generator_conv_kernel_sizes, generator_conv_strides,\n",
    "                 generator_activation,\n",
    "                 generator_batch_norm_momentum, generator_dropout_rate):\n",
    "        self.generator_initial_dense_layer_size = generator_initial_dense_layer_size\n",
    "        self.generator_n_layers = generator_n_layers\n",
    "        self.generator_upsamplings = generator_upsamplings\n",
    "        self.generator_conv_filters = generator_conv_filters\n",
    "        self.generator_conv_kernel_sizes = generator_conv_kernel_sizes\n",
    "        self.generator_conv_strides = generator_conv_strides\n",
    "        self.latent_dim = latent_dim\n",
    "        self.generator_activation = generator_activation\n",
    "        self.generator_batch_norm_momentum = generator_batch_norm_momentum\n",
    "        self.generator_dropout_rate = generator_dropout_rate\n",
    "\n",
    "        self.input = Input(shape=(self.latent_dim,), name=\"generator_input\")\n",
    "\n",
    "        x = Dense(np.prod(self.generator_initial_dense_layer_size))(self.input) # Connect the input to a dense layer\n",
    "\n",
    "        if self.generator_batch_norm_momentum:\n",
    "            x = BatchNormalization(momentum=self.generator_batch_norm_momentum)(x)\n",
    "\n",
    "        x = Activation(self.generator_activation)(x)\n",
    "\n",
    "        x = Reshape(self.generator_initial_dense_layer_size)(x) # Reshape latent space vector for convolutional transpose layers\n",
    "\n",
    "        if self.generator_dropout_rate:\n",
    "            x = Dropout(rate=self.generator_dropout_rate)(x)\n",
    "\n",
    "        for i in range(self.generator_n_layers):\n",
    "            if self.generator_upsamplings[i]:\n",
    "                x = UpSampling2D(name=\"generator_up_sampling_\" + str(i))(x)\n",
    "                conv_layer = Conv2D(filters=self.generator_conv_filters[i],\n",
    "                                    kernel_size=self.generator_conv_kernel_sizes[i],\n",
    "                                    strides=self.generator_conv_strides[i],\n",
    "                                    padding=\"same\",\n",
    "                                    name=\"generator_conv_\" + str(i))\n",
    "                x = conv_layer(x)\n",
    "            else:\n",
    "                conv_t_layer = Conv2DTranspose(filters=self.generator_conv_filters[i],\n",
    "                                               kernel_size=self.generator_conv_kernel_sizes[i],\n",
    "                                               strides=self.generator_conv_strides[i],\n",
    "                                               padding=\"same\",\n",
    "                                               name=\"generator_conv_t_\" + str(i))\n",
    "                x = conv_t_layer(x)\n",
    "\n",
    "            if i < self.generator_n_layers - 1:\n",
    "                if self.generator_batch_norm_momentum:\n",
    "                    x = BatchNormalization(momentum=self.generator_batch_norm_momentum)(x)\n",
    "                x = Activation(activation=\"relu\")(x)\n",
    "            else:\n",
    "                x = Activation(activation=\"tanh\")(x)\n",
    "\n",
    "        self.output = x\n",
    "\n",
    "        self.model = Model(self.input, self.output, name=\"generator\")\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(Layer):\n",
    "    def __init__(self, batch_size):\n",
    "        super(RandomWeightedAverage, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def call(self, inputs):\n",
    "        real_images = inputs[0]\n",
    "        generated_images = inputs[1]\n",
    "        alpha = tf.random.uniform(shape=[self.batch_size, 1, 1, 1])\n",
    "        return (alpha * real_images) + ((1 - alpha) * generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeAdversarialNetwork():\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim, critic_n_layers, critic_conv_filters, critic_conv_kernel_sizes, critic_conv_strides,\n",
    "                 critic_activation, critic_learning_rate,\n",
    "                 critic_batch_norm_momentum, critic_dropout_rate,\n",
    "                 latent_dim, generator_initial_dense_layer_size, generator_n_layers, generator_upsamplings, generator_conv_filters, generator_conv_kernel_sizes, generator_conv_strides,\n",
    "                 generator_activation, generator_learning_rate,\n",
    "                 generator_batch_norm_momentum, generator_dropout_rate,\n",
    "                 batch_size, gradient_loss_weight):\n",
    "        self.input_dim = input_dim\n",
    "        self.critic_n_layers = critic_n_layers\n",
    "        self.critic_conv_filters = critic_conv_filters\n",
    "        self.critic_conv_kernel_sizes = critic_conv_kernel_sizes\n",
    "        self.critic_conv_strides = critic_conv_strides\n",
    "        self.critic_activation = critic_activation\n",
    "        self.critic_learning_rate = critic_learning_rate\n",
    "        self.critic_batch_norm_momentum = critic_batch_norm_momentum\n",
    "        self.critic_dropout_rate = critic_dropout_rate\n",
    "        \n",
    "        self.generator_initial_dense_layer_size = generator_initial_dense_layer_size\n",
    "        self.generator_n_layers = generator_n_layers\n",
    "        self.generator_upsamplings = generator_upsamplings\n",
    "        self.generator_conv_filters = generator_conv_filters\n",
    "        self.generator_conv_kernel_sizes = generator_conv_kernel_sizes\n",
    "        self.generator_conv_strides = generator_conv_strides\n",
    "        self.latent_dim = latent_dim\n",
    "        self.generator_activation = generator_activation\n",
    "        self.generator_learning_rate = generator_learning_rate\n",
    "        self.generator_batch_norm_momentum = generator_batch_norm_momentum\n",
    "        self.generator_dropout_rate = generator_dropout_rate\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.gradient_loss_weight = gradient_loss_weight\n",
    "        self.epoch = 0\n",
    "        self.critic_losses = []\n",
    "        self.generator_losses = []\n",
    "\n",
    "        # Create critic\n",
    "        self.critic = Critic(self.input_dim,\n",
    "                                    self.critic_n_layers, self.critic_conv_filters, self.critic_conv_kernel_sizes, self.critic_conv_strides,\n",
    "                                    self.critic_activation,\n",
    "                                    self.critic_batch_norm_momentum, self.critic_dropout_rate)\n",
    "        \n",
    "        # Create Generator\n",
    "        self.generator = Generator(self.latent_dim, self.generator_initial_dense_layer_size,\n",
    "                                   self.generator_n_layers, self.generator_upsamplings, self.generator_conv_filters, self.generator_conv_kernel_sizes, self.generator_conv_strides,\n",
    "                                   self.generator_activation,\n",
    "                                   self.generator_batch_norm_momentum, self.generator_dropout_rate)\n",
    "\n",
    "        # Define loss functions\n",
    "        def wasserstein_loss(y_true, y_pred):\n",
    "            return -K.mean(y_true * y_pred)\n",
    "        \n",
    "        def gradient_penalty_loss(y_true, y_pred, interpolated_samples):\n",
    "            gradients = K.gradients(y_pred, interpolated_samples)[0] # Gradients of the predictions for the interpolated images (y_pred) with respect to the input (interpolated_samples)\n",
    "            gradient_l2_norm = K.sqrt(\n",
    "                K.sum(\n",
    "                    K.square(gradients),\n",
    "                    axis=np.arange(1, len(gradients.shape))\n",
    "                )\n",
    "            )\n",
    "            gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "            return K.mean(gradient_penalty)\n",
    "        \n",
    "        # Define utility function\n",
    "        # @tf.function\n",
    "        def random_weighted_average(inputs):\n",
    "            alpha = tf.random.uniform(shape=(self.batch_size, 1, 1, 1))\n",
    "            return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "        \n",
    "        # Compile model that trains the critic\n",
    "        self.set_trainable(self.generator.model, False) # Freeze generator while training critic\n",
    "\n",
    "        # Real images\n",
    "        real_img = Input(shape=self.input_dim, name=\"adversarial_critic_real_img_input\")\n",
    "        validity_real = self.critic.model(real_img)\n",
    "\n",
    "        # Generated image\n",
    "        generated_img = Input(shape=self.input_dim, name=\"adversarial_critic_generated_img_input\")\n",
    "        validity_generated = self.critic.model(generated_img)\n",
    "\n",
    "        # Weighted average between real and generated images\n",
    "        interpolated_img = RandomWeightedAverage(self.batch_size)([real_img, generated_img])\n",
    "        # interpolated_img = Lambda(lambda x: RandomWeightedAverage(self.batch_size)(x), name=\"random_weighted_images\")([real_img, generated_img])\n",
    "        # interpolated_img = Lambda(random_weighted_average, output_shape=lambda x: x[0], name=\"random_weighted_images\")([real_img, generated_img])\n",
    "        validity_interpolated = self.critic.model(interpolated_img)\n",
    "        # validity_interpolated = CustomLambdaLayer()(self.critic.model, interpolated_img)\n",
    "\n",
    "        self.critic_model = Model(inputs=[real_img, generated_img],\n",
    "                                  outputs=[validity_real, validity_generated, validity_interpolated],\n",
    "                                  name=\"adversarial_critic\")\n",
    "\n",
    "        # Use Python partial to provide loss function with additional 'interpolated_samples' argument\n",
    "        partial_gp_loss = partial(gradient_penalty_loss,\n",
    "                                  interpolated_samples=interpolated_img)\n",
    "        partial_gp_loss.__name__ = \"gradient_penalty\" # Keras requires function names\n",
    "\n",
    "        self.critic_model.compile(optimizer=Adam(learning_rate=self.critic_learning_rate, beta_1=0.5),\n",
    "                                  loss=[wasserstein_loss, wasserstein_loss, partial_gp_loss],\n",
    "                                  loss_weights=[1, 1, self.gradient_loss_weight])\n",
    "        self.set_trainable(self.generator.model, True) # Unfreeze generator while training critic\n",
    "        \n",
    "        # Compile model that trains the generator\n",
    "        self.set_trainable(self.critic.model, False)\n",
    "        self.input = Input(shape=(self.latent_dim,), name=\"generative_adversarial_network_input\")\n",
    "        self.output = self.critic.model(self.generator.model(self.input))\n",
    "        self.model = Model(self.input, self.output, name=\"generative_adversarial_network\")\n",
    "        self.model.compile(optimizer=RMSprop(learning_rate=self.generator_learning_rate),\n",
    "                           loss=wasserstein_loss,\n",
    "                           metrics=[\"accuracy\"])\n",
    "        self.set_trainable(self.critic.model, True)\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def plot_model(self, run_folder):\n",
    "        plot_model(self.model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes=True, show_layer_names=True)\n",
    "        plot_model(self.critic.model, to_file=os.path.join(run_folder ,'viz/critic.png'), show_shapes=True, show_layer_names=True)\n",
    "        plot_model(self.generator.model, to_file=os.path.join(run_folder ,'viz/generator.png'), show_shapes=True, show_layer_names=True)\n",
    "        plot_model(self.critic_model, to_file=os.path.join(run_folder ,'viz/adversarial_critic.png'), show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    def load_weights(self, filepath=\"model/weights/params.pkl\"):\n",
    "        self.model.load_weights(filepath)\n",
    "\n",
    "    def set_trainable(self, model, value):\n",
    "        model.trainable = value\n",
    "        for l in model.layers:\n",
    "            l.trainable = value\n",
    "\n",
    "    def fit_critic(self, X_train):\n",
    "        # Real images\n",
    "        idx = np.random.randint(0, X_train.shape[0], self.batch_size)\n",
    "        real_imgs = X_train[idx]\n",
    "        valid = np.ones((self.batch_size, 1), dtype=np.float32)\n",
    "\n",
    "        # Generated images\n",
    "        noise = np.random.normal(0, 1, (self.batch_size, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        generated = -np.ones((self.batch_size, 1), dtype=np.float32)\n",
    "\n",
    "        # Random weighted images\n",
    "        random_weighted = np.zeros((self.batch_size, 1), dtype=np.float32)\n",
    "\n",
    "        c_loss = self.critic_model.train_on_batch(x=[real_imgs, gen_imgs], y=[valid, generated, random_weighted])\n",
    "\n",
    "        return c_loss\n",
    "    \n",
    "    def fit_generator(self):\n",
    "        valid = np.ones((self.batch_size, 1)) # Forces the generator to produce images considered as valid by the critic\n",
    "        noise = np.random.normal(0, 1, (self.batch_size, self.latent_dim))\n",
    "        return self.model.train_on_batch(noise, valid)\n",
    "    \n",
    "    def fit(self, X_train, epochs):\n",
    "\n",
    "        for epoch in range(self.epoch, self.epoch + epochs):\n",
    "            \n",
    "            # Train the critic multiple times\n",
    "            for _ in range(5):\n",
    "                c_loss = self.fit_critic(X_train)\n",
    "\n",
    "            # Train the generator once\n",
    "            g_loss = self.fit_generator()\n",
    "\n",
    "            print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f] [G acc: %.3f]\" % (epoch,\n",
    "                                                                                                                     c_loss[0], c_loss[1], c_loss[2], c_loss[3], c_loss[4], c_loss[5],\n",
    "                                                                                                                     g_loss[0], g_loss[1]))\n",
    "\n",
    "            self.critic_losses.append(c_loss)\n",
    "            self.generator_losses.append(g_loss)\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def save(self, folder=\"model\"):\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            os.makedirs(os.path.join(folder, 'viz'))\n",
    "            os.makedirs(os.path.join(folder, 'weights'))\n",
    "            os.makedirs(os.path.join(folder, 'images'))\n",
    "\n",
    "        with open(os.path.join(folder, 'weights/params.pkl'), 'wb') as f:\n",
    "            pickle.dump([self.input_dim,\n",
    "                         self.critic_conv_filters,\n",
    "                         self.critic_conv_kernel_sizes,\n",
    "                         self.critic_conv_strides,\n",
    "                         self.critic_batch_norm_momentum,\n",
    "                         self.critic_dropout_rate,\n",
    "                         self.latent_dim,\n",
    "                         self.generator_conv_filters,\n",
    "                         self.generator_conv_kernel_sizes,\n",
    "                         self.generator_conv_strides,\n",
    "                         self.generator_batch_norm_momentum,\n",
    "                         self.generator_dropout_rate], f)\n",
    "        self.plot_model(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1\n",
      "### 2\n",
      "### 3\n"
     ]
    }
   ],
   "source": [
    "LATENT_DIM = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "generative_adversarial_network = GenerativeAdversarialNetwork(input_dim=(28,28,1),\n",
    "                                                              critic_n_layers=4,\n",
    "                                                              critic_conv_filters=[64,64,128,128],\n",
    "                                                              critic_conv_kernel_sizes=[5,5,5,5],\n",
    "                                                              critic_conv_strides=[2,2,2,1],\n",
    "                                                              critic_activation='relu',\n",
    "                                                              critic_learning_rate=0.0008,\n",
    "                                                              critic_batch_norm_momentum=None,\n",
    "                                                              critic_dropout_rate=0.4,\n",
    "                                                              latent_dim=LATENT_DIM,\n",
    "                                                              generator_initial_dense_layer_size=(7,7,64),\n",
    "                                                              generator_n_layers=4,\n",
    "                                                              generator_upsamplings=[True,False,True,False],\n",
    "                                                              generator_conv_filters=[128,64,64,1],\n",
    "                                                              generator_conv_kernel_sizes=[5,5,5,5],\n",
    "                                                              generator_conv_strides=[1,1,1,1],\n",
    "                                                              generator_activation='relu',\n",
    "                                                              generator_learning_rate=0.0004,\n",
    "                                                              generator_batch_norm_momentum=0.9,\n",
    "                                                              generator_dropout_rate=None,\n",
    "                                                              batch_size=BATCH_SIZE,\n",
    "                                                              gradient_loss_weight=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_adversarial_network.plot_model(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"critic\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " critic_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " critic_conv_0 (Conv2D)      (None, 6, 6, 64)          1664      \n",
      "                                                                 \n",
      " critic_activation_0 (Activ  (None, 6, 6, 64)          0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " critic_conv_1 (Conv2D)      (None, 2, 2, 64)          102464    \n",
      "                                                                 \n",
      " critic_activation_1 (Activ  (None, 2, 2, 64)          0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " critic_conv_2 (Conv2D)      (None, 1, 1, 128)         204928    \n",
      "                                                                 \n",
      " critic_activation_2 (Activ  (None, 1, 1, 128)         0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " critic_conv_3 (Conv2D)      (None, 1, 1, 128)         409728    \n",
      "                                                                 \n",
      " critic_activation_3 (Activ  (None, 1, 1, 128)         0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " critic_output (Dense)       (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 718913 (2.74 MB)\n",
      "Trainable params: 718913 (2.74 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generative_adversarial_network.critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " generator_input (InputLaye  [(None, 100)]             0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3136)              316736    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 3136)              12544     \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 3136)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " generator_up_sampling_0 (U  (None, 14, 14, 64)        0         \n",
      " pSampling2D)                                                    \n",
      "                                                                 \n",
      " generator_conv_0 (Conv2D)   (None, 14, 14, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 14, 14, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " generator_conv_t_1 (Conv2D  (None, 14, 14, 64)        204864    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 14, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " generator_up_sampling_2 (U  (None, 28, 28, 64)        0         \n",
      " pSampling2D)                                                    \n",
      "                                                                 \n",
      " generator_conv_2 (Conv2D)   (None, 28, 28, 64)        102464    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 28, 28, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " generator_conv_t_3 (Conv2D  (None, 28, 28, 1)         1601      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 844161 (3.22 MB)\n",
      "Trainable params: 837377 (3.19 MB)\n",
      "Non-trainable params: 6784 (26.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generative_adversarial_network.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generative_adversarial_network\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " generative_adversarial_net  [(None, 100)]             0         \n",
      " work_input (InputLayer)                                         \n",
      "                                                                 \n",
      " generator (Functional)      (None, 28, 28, 1)         844161    \n",
      "                                                                 \n",
      " critic (Functional)         (None, 1)                 718913    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1563074 (5.96 MB)\n",
      "Trainable params: 1556290 (5.94 MB)\n",
      "Non-trainable params: 6784 (26.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generative_adversarial_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"adversarial_critic\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " adversarial_critic_real_im  [(None, 28, 28, 1)]          0         []                            \n",
      " g_input (InputLayer)                                                                             \n",
      "                                                                                                  \n",
      " adversarial_critic_generat  [(None, 28, 28, 1)]          0         []                            \n",
      " ed_img_input (InputLayer)                                                                        \n",
      "                                                                                                  \n",
      " random_weighted_average (R  (64, 28, 28, 1)              0         ['adversarial_critic_real_img_\n",
      " andomWeightedAverage)                                              input[0][0]',                 \n",
      "                                                                     'adversarial_critic_generated\n",
      "                                                                    _img_input[0][0]']            \n",
      "                                                                                                  \n",
      " critic (Functional)         (None, 1)                    718913    ['adversarial_critic_real_img_\n",
      "                                                                    input[0][0]',                 \n",
      "                                                                     'adversarial_critic_generated\n",
      "                                                                    _img_input[0][0]',            \n",
      "                                                                     'random_weighted_average[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 718913 (2.74 MB)\n",
      "Trainable params: 718913 (2.74 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generative_adversarial_network.critic_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist_dataset = mnist.load_data()\n",
    "(trainset, testset) = (mnist_dataset[0], mnist_dataset[1])\n",
    "(X_train, y_train) = trainset\n",
    "(X_test, y_test) = testset\n",
    "\n",
    "# Preprocess data (convert to float and scale to between 0 and 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "\n",
    "# Preprocess data (convert to uint8)\n",
    "# y_train = y_train.astype('uint8')\n",
    "# y_test = y_test.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 74ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/fabien/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_17304/3478761015.py\", line 56, in gradient_penalty_loss  *\n        gradients = K.gradients(y_pred, interpolated_samples)[0] # Gradients of the predictions for the interpolated images (y_pred) with respect to the input (interpolated_samples)\n    File \"/home/fabien/anaconda3/lib/python3.9/site-packages/keras/src/backend.py\", line 4693, in gradients  **\n        return tf.compat.v1.gradients(\n    File \"/home/fabien/anaconda3/lib/python3.9/site-packages/keras/src/engine/keras_tensor.py\", line 285, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(64, 28, 28, 1), dtype=tf.float32, name=None), name='random_weighted_average/add:0', description=\"created by layer 'random_weighted_average'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/fabien/generative_ai/Deep Generative Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb Cell 23\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/fabien/generative_ai/Deep%20Generative%20Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m generative_adversarial_network\u001b[39m.\u001b[39;49mfit(X_train, EPOCHS)\n",
      "\u001b[1;32m/home/fabien/generative_ai/Deep Generative Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb Cell 23\u001b[0m line \u001b[0;36mGenerativeAdversarialNetwork.fit\u001b[0;34m(self, X_train, epochs)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/fabien/generative_ai/Deep%20Generative%20Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb#X30sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch \u001b[39m+\u001b[39m epochs):\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/fabien/generative_ai/Deep%20Generative%20Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb#X30sZmlsZQ%3D%3D?line=159'>160</a>\u001b[0m     \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/fabien/generative_ai/Deep%20Generative%20Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb#X30sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m     \u001b[39m# Train the critic multiple times\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/fabien/generative_ai/Deep%20Generative%20Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb#X30sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/fabien/generative_ai/Deep%20Generative%20Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb#X30sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m         c_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_critic(X_train)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/fabien/generative_ai/Deep%20Generative%20Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb#X30sZmlsZQ%3D%3D?line=164'>165</a>\u001b[0m     \u001b[39m# Train the generator once\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/fabien/generative_ai/Deep%20Generative%20Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb#X30sZmlsZQ%3D%3D?line=165'>166</a>\u001b[0m     g_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_generator()\n",
      "\u001b[1;32m/home/fabien/generative_ai/Deep Generative Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb Cell 23\u001b[0m line \u001b[0;36mGenerativeAdversarialNetwork.fit_critic\u001b[0;34m(self, X_train)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/fabien/generative_ai/Deep%20Generative%20Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb#X30sZmlsZQ%3D%3D?line=144'>145</a>\u001b[0m \u001b[39m# Random weighted images\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/fabien/generative_ai/Deep%20Generative%20Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb#X30sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m random_weighted \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size, \u001b[39m1\u001b[39m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/fabien/generative_ai/Deep%20Generative%20Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb#X30sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m c_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcritic_model\u001b[39m.\u001b[39;49mtrain_on_batch(x\u001b[39m=\u001b[39;49m[real_imgs, gen_imgs], y\u001b[39m=\u001b[39;49m[valid, generated, random_weighted])\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/fabien/generative_ai/Deep%20Generative%20Models/wasserstein_generative_adversarial_network_gradient_penalty/wasserstein_generative_adversarial_network_gradient_penalty.ipynb#X30sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m \u001b[39mreturn\u001b[39;00m c_loss\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:2787\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2783\u001b[0m     iterator \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39msingle_batch_iterator(\n\u001b[1;32m   2784\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[1;32m   2785\u001b[0m     )\n\u001b[1;32m   2786\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_train_function()\n\u001b[0;32m-> 2787\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   2789\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2790\u001b[0m \u001b[39mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileg328y6de.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1380\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[1;32m   1381\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m     )\n\u001b[1;32m   1383\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1384\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[1;32m   1385\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1386\u001b[0m     outputs,\n\u001b[1;32m   1387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1388\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1389\u001b[0m )\n\u001b[1;32m   1390\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1373\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1373\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[1;32m   1374\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1151\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m   1150\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(x, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1151\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[1;32m   1152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1153\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1209\u001b[0m, in \u001b[0;36mModel.compute_loss\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the total loss, validate it, and return it.\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \n\u001b[1;32m   1160\u001b[0m \u001b[39mSubclasses can optionally override this method to provide custom loss\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[39m  is the case when called by `Model.test_step`).\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m \u001b[39mdel\u001b[39;00m x  \u001b[39m# The default implementation does not use `x`.\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompiled_loss(\n\u001b[1;32m   1210\u001b[0m     y, y_pred, sample_weight, regularization_losses\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlosses\n\u001b[1;32m   1211\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/engine/compile_utils.py:277\u001b[0m, in \u001b[0;36mLossesContainer.__call__\u001b[0;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[1;32m    275\u001b[0m y_t, y_p, sw \u001b[39m=\u001b[39m match_dtype_and_rank(y_t, y_p, sw)\n\u001b[1;32m    276\u001b[0m sw \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mapply_mask(y_p, sw, losses_utils\u001b[39m.\u001b[39mget_mask(y_p))\n\u001b[0;32m--> 277\u001b[0m loss_value \u001b[39m=\u001b[39m loss_obj(y_t, y_p, sample_weight\u001b[39m=\u001b[39;49msw)\n\u001b[1;32m    279\u001b[0m total_loss_mean_value \u001b[39m=\u001b[39m loss_value\n\u001b[1;32m    280\u001b[0m \u001b[39m# Correct for the `Mean` loss metrics counting each replica as a\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39m# batch.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/losses.py:143\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     call_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m    140\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[1;32m    141\u001b[0m     )\n\u001b[0;32m--> 143\u001b[0m losses \u001b[39m=\u001b[39m call_fn(y_true, y_pred)\n\u001b[1;32m    145\u001b[0m in_mask \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mget_mask(y_pred)\n\u001b[1;32m    146\u001b[0m out_mask \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mget_mask(losses)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/losses.py:270\u001b[0m, in \u001b[0;36mLossFunctionWrapper.call\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    263\u001b[0m     y_pred, y_true \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39msqueeze_or_expand_dimensions(\n\u001b[1;32m    264\u001b[0m         y_pred, y_true\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    267\u001b[0m ag_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m    268\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[1;32m    269\u001b[0m )\n\u001b[0;32m--> 270\u001b[0m \u001b[39mreturn\u001b[39;00m ag_fn(y_true, y_pred, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fn_kwargs)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filevort65bo.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__gradient_penalty_loss\u001b[0;34m(y_true, y_pred, interpolated_samples)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m gradients \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(K)\u001b[39m.\u001b[39mgradients, (ag__\u001b[39m.\u001b[39mld(y_pred), ag__\u001b[39m.\u001b[39mld(interpolated_samples)), \u001b[39mNone\u001b[39;00m, fscope)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m gradient_l2_norm \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(K)\u001b[39m.\u001b[39msqrt, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(K)\u001b[39m.\u001b[39msum, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(K)\u001b[39m.\u001b[39msquare, (ag__\u001b[39m.\u001b[39mld(gradients),), \u001b[39mNone\u001b[39;00m, fscope),), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(np)\u001b[39m.\u001b[39marange, (\u001b[39m1\u001b[39m, ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mlen\u001b[39m), (ag__\u001b[39m.\u001b[39mld(gradients)\u001b[39m.\u001b[39mshape,), \u001b[39mNone\u001b[39;00m, fscope)), \u001b[39mNone\u001b[39;00m, fscope)), fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m gradient_penalty \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(K)\u001b[39m.\u001b[39msquare, (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m ag__\u001b[39m.\u001b[39mld(gradient_l2_norm),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/backend.py:4693\u001b[0m, in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   4681\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.backend.gradients\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4682\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_generate_docs\n\u001b[1;32m   4683\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgradients\u001b[39m(loss, variables):\n\u001b[1;32m   4684\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the gradients of `loss` w.r.t. `variables`.\u001b[39;00m\n\u001b[1;32m   4685\u001b[0m \n\u001b[1;32m   4686\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4691\u001b[0m \u001b[39m        A gradients tensor.\u001b[39;00m\n\u001b[1;32m   4692\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4693\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mgradients(\n\u001b[1;32m   4694\u001b[0m         loss, variables, colocate_gradients_with_ops\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m   4695\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/engine/keras_tensor.py:285\u001b[0m, in \u001b[0;36mKerasTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    286\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are passing \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, an intermediate Keras symbolic \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput/output, to a TF API that does not allow registering custom \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdispatchers, such as `tf.cond`, `tf.function`, gradient tapes, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `tf.map_fn`. Keras Functional model construction only supports \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTF API calls that *do* support dispatching, such as `tf.math.add` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `tf.reshape`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOther APIs cannot be called directly on symbolic Keras\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minputs/outputs. You can work around \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthis limitation by putting the operation in a custom Keras layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`call` and calling that layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mon this symbolic input/output.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/fabien/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_17304/3478761015.py\", line 56, in gradient_penalty_loss  *\n        gradients = K.gradients(y_pred, interpolated_samples)[0] # Gradients of the predictions for the interpolated images (y_pred) with respect to the input (interpolated_samples)\n    File \"/home/fabien/anaconda3/lib/python3.9/site-packages/keras/src/backend.py\", line 4693, in gradients  **\n        return tf.compat.v1.gradients(\n    File \"/home/fabien/anaconda3/lib/python3.9/site-packages/keras/src/engine/keras_tensor.py\", line 285, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(64, 28, 28, 1), dtype=tf.float32, name=None), name='random_weighted_average/add:0', description=\"created by layer 'random_weighted_average'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n"
     ]
    }
   ],
   "source": [
    "generative_adversarial_network.fit(X_train, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot critic losses\n",
    "plt.plot([row[0] for row in generative_adversarial_network.critic_losses], label=\"loss\")\n",
    "plt.plot([row[1] for row in generative_adversarial_network.critic_losses], label=\"loss (real images)\")\n",
    "plt.plot([row[2] for row in generative_adversarial_network.critic_losses], label=\"loss (generated images)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot critic accuracy\n",
    "plt.plot([row[3] for row in generative_adversarial_network.critic_losses], label=\"accuracy\")\n",
    "plt.plot([row[4] for row in generative_adversarial_network.critic_losses], label=\"accuracy (real images)\")\n",
    "plt.plot([row[5] for row in generative_adversarial_network.critic_losses], label=\"accuracy (generated images)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot generator loss\n",
    "plt.plot([row[0] for row in generative_adversarial_network.generator_losses], label=\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot generator accuracy\n",
    "plt.plot([row[1] for row in generative_adversarial_network.generator_losses], label=\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_adversarial_network.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variational_autoencoder.load_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modifier_vector(size, dim, value):\n",
    "    v = np.zeros(shape=(1,size))\n",
    "    v[dim] = value\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_PRED = 5\n",
    "\n",
    "latent_vector_init = np.random.random(size=(1,LATENT_DIM))\n",
    "\n",
    "latent_vectors = tf.data.Dataset.from_tensor_slices([latent_vector_init + modifier_vector(LATENT_DIM, 0, i) for i in range(NB_PRED)])\n",
    "\n",
    "# list(latent_vectors.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_compare_images(img1, img2):\n",
    "    return np.mean(np.abs(img1 - img2))\n",
    "\n",
    "def find_closest(img):\n",
    "    closest = None\n",
    "    closest_l1 = None\n",
    "    for i in X_train:\n",
    "        l1 = l1_compare_images(img, i)\n",
    "        if closest_l1 is None or l1 < closest_l1:\n",
    "            closest = i\n",
    "            closest_l1 = l1\n",
    "    for i in X_test:\n",
    "        l1 = l1_compare_images(img, i)\n",
    "        if closest_l1 is None or l1 < closest_l1:\n",
    "            closest = i\n",
    "            closest_l1 = l1\n",
    "    return closest, closest_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = generative_adversarial_network.generator.predict(latent_vectors)\n",
    "\n",
    "closest_in_dataset = []\n",
    "latent_vectors_iterator = iter(latent_vectors)\n",
    "for i in range(NB_PRED):\n",
    "    closest_in_dataset.append(find_closest(predictions[i]))\n",
    "    plt.figure(figsize=((5,5)))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(predictions[i], cmap=\"gray\")\n",
    "    plt.title(f\"{latent_vectors_iterator.get_next()}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(closest_in_dataset[i][0], cmap=\"gray\")\n",
    "    plt.title(f\"l1 = {closest_in_dataset[i][1]}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs are notoriously hard to train because:\n",
    "- The losses can oscillate leading to bad results. This is called **Oscillating Loss**.\n",
    "- The generator can find a small number of samples that fool the critic (called *modes*), it starts to map every point in the latent space to this observation and the gradient of the loss function collapses to 0 preventing it to learn properly (even if we train the critic in a way it is not fooled anymore by these observations, the generator has become numb and will simply find other modes). This phenomenon is know as **Mode Collapse**.\n",
    "- The lack of correlation between the generator loss and the image quality makes the GAN hard to train. The generator is graded against a critic that improves overtime so the loss can increase while the image quality improves. GANs use an **Uninformative Loss**.\n",
    "- GANs uses a lot of **Hyperparameters** that require fine-tuning.\n",
    "\n",
    "In order to counter some of those effects, some improvements can be made to the basic GAN architecture. For instance the Wasserstein GAN is an attempt a improving GANs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

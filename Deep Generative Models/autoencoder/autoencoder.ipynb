{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This deep neural networks made of two parts:\n",
    "- An encoder: a network that learns to represent/compress the high-dimensional input data into a lower dimensional latent space\n",
    "- A decoder: a network that learns to decompress a given representation/vector in the latent space to a high-dimensional representation\n",
    "\n",
    "Often used to remove noise from images.\n",
    "\n",
    "It is really easy to create an autoencoder using Keras Model Subclassing API as show in this [Tensorflow tutorial](https://www.tensorflow.org/tutorials/generative/autoencoder).\n",
    "\n",
    "See also: https://drive.google.com/drive/folders/1KPsQvVDUcJzsDRw7YU-F2TvPLGdcV0An\n",
    "\n",
    "Let's build an autoencoder \"from scratch\" to have a better understanding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand Made Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, Flatten, Dense, Reshape, Conv2DTranspose, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# Clear TensorFlow session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(Callback):\n",
    "    \n",
    "    def __init__(self, run_folder, print_every_n_batches, initial_epoch, vae):\n",
    "        self.epoch = initial_epoch\n",
    "        self.run_folder = run_folder\n",
    "        self.print_every_n_batches = print_every_n_batches\n",
    "        self.vae = vae\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):  \n",
    "        if batch % self.print_every_n_batches == 0:\n",
    "            z_new = np.random.normal(size = (1,self.vae.latent_dim))\n",
    "            reconst = self.vae.decoder.predict(np.array(z_new))[0].squeeze()\n",
    "\n",
    "            filepath = os.path.join(self.run_folder, 'images', 'img_' + str(self.epoch).zfill(3) + '_' + str(batch) + '.jpg')\n",
    "            if len(reconst.shape) == 2:\n",
    "                plt.imsave(filepath, reconst, cmap='gray_r')\n",
    "            else:\n",
    "                plt.imsave(filepath, reconst)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch += 1\n",
    "\n",
    "\n",
    "\n",
    "def step_decay_schedule(initial_lr, decay_factor=0.5, step_size=1):\n",
    "    '''\n",
    "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
    "    '''\n",
    "    def schedule(epoch):\n",
    "        new_lr = initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
    "        \n",
    "        return new_lr\n",
    "\n",
    "    return LearningRateScheduler(schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder():\n",
    "\n",
    "    def __init__(self, input_dim, encoder_n_layers, encoder_conv_filters, encoder_conv_kernel_sizes, encoder_conv_strides, latent_dim, batch_norm, drop_out):\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_n_layers = encoder_n_layers\n",
    "        self.encoder_conv_filters = encoder_conv_filters\n",
    "        self.encoder_conv_kernel_sizes = encoder_conv_kernel_sizes\n",
    "        self.encoder_conv_strides = encoder_conv_strides\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_norm = batch_norm\n",
    "        self.drop_out = drop_out\n",
    "\n",
    "        self.input = Input(shape=self.input_dim, name=\"encoder_input\")\n",
    "\n",
    "        x = self.input\n",
    "\n",
    "        for i in range(self.encoder_n_layers):\n",
    "            conv_layer = Conv2D(filters=self.encoder_conv_filters[i],\n",
    "                                kernel_size=self.encoder_conv_kernel_sizes[i],\n",
    "                                strides=self.encoder_conv_strides[i],\n",
    "                                padding=\"same\",\n",
    "                                name=\"encoder_conv_\" + str(i))\n",
    "            x = conv_layer(x)\n",
    "            x = LeakyReLU(name=\"encoder_leaky_relu_\" + str(i))(x)\n",
    "\n",
    "            if self.use_batch_norm:\n",
    "                x = BatchNormalization()(x)\n",
    "\n",
    "            if self.use_dropout:\n",
    "                x = Dropout(rate = 0.25)(x)\n",
    "\n",
    "        # self.shape_before_flattening = tf.keras.backend.int_shape(x)[1:] # See decoder\n",
    "        self.shape_before_flattening = x.shape[1:] # See decoder\n",
    "\n",
    "        x = Flatten(name=\"encoder_flatten\")(x)\n",
    "\n",
    "        self.output = Dense(self.latent_dim, name=\"output\")(x)\n",
    "\n",
    "        self.model = Model(self.input, self.output)\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder():\n",
    "\n",
    "    def __init__(self, latent_dim, shape_before_flattening, decoder_n_layers, decoder_conv_t_filters, decoder_conv_t_kernel_sizes, decoder_conv_t_strides, output_dim, batch_norm, drop_out):\n",
    "        self.output_dim = output_dim\n",
    "        self.shape_before_flattening = shape_before_flattening\n",
    "        self.decoder_n_layers = decoder_n_layers\n",
    "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
    "        self.decoder_conv_t_kernel_sizes = decoder_conv_t_kernel_sizes\n",
    "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_norm = batch_norm\n",
    "        self.drop_out = drop_out\n",
    "\n",
    "        self.input = Input(shape=(self.latent_dim,), name=\"decoder_input\")\n",
    "\n",
    "        x = Dense(np.prod(shape_before_flattening))(self.input) # Connect the input to a dense layer\n",
    "\n",
    "        x = Reshape(self.shape_before_flattening)(x) # Reshape latent space vector for convolutional transpose layers\n",
    "\n",
    "        for i in range(self.decoder_n_layers):\n",
    "            conv_t_layer = Conv2DTranspose(filters=self.decoder_conv_t_filters[i],\n",
    "                                           kernel_size=self.decoder_conv_t_kernel_sizes[i],\n",
    "                                           strides=self.decoder_conv_t_strides[i],\n",
    "                                           padding=\"same\",\n",
    "                                           name=\"decoder_conv_t_\" + str(i))\n",
    "            x = conv_t_layer(x)\n",
    "\n",
    "            if i < self.decoder_n_layers - 1:\n",
    "                x = LeakyReLU(name=\"decoder_leaky_relu_\" + str(i))(x)\n",
    "                \n",
    "                if self.use_batch_norm:\n",
    "                    x = BatchNormalization()(x)\n",
    "                if self.use_dropout:\n",
    "                    x = Dropout(rate = 0.25)(x)\n",
    "            else:\n",
    "                # x = Activation(\"sigmoid\")(x)\n",
    "                x = Activation(tf.keras.activations.sigmoid, name=\"decoder_sigmoid_\" + str(i))(x)\n",
    "\n",
    "        self.output = x\n",
    "\n",
    "        self.model = Model(self.input, self.output)\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder():\n",
    "\n",
    "    def __init__(self, input_dim,\n",
    "                 encoder_n_layers, encoder_conv_filters, encoder_conv_kernel_sizes, encoder_conv_strides,\n",
    "                 latent_dim,\n",
    "                 decoder_n_layers, decoder_conv_t_filters, decoder_conv_t_kernel_sizes, decoder_conv_t_strides,\n",
    "                 output_dim,\n",
    "                 learning_rate, batch_norm, drop_out):\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_n_layers = encoder_n_layers\n",
    "        self.encoder_conv_filters = encoder_conv_filters\n",
    "        self.encoder_conv_kernel_sizes = encoder_conv_kernel_sizes\n",
    "        self.encoder_conv_strides = encoder_conv_strides\n",
    "        self.latent_dim = latent_dim\n",
    "        self.decoder_n_layers = decoder_n_layers\n",
    "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
    "        self.decoder_conv_t_kernel_sizes = decoder_conv_t_kernel_sizes\n",
    "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
    "        self.output_dim = output_dim\n",
    "        self.batch_norm = batch_norm\n",
    "        self.dropout = drop_out\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Create encoder\n",
    "        self.encoder = Encoder(self.input_dim,\n",
    "                               self.encoder_n_layers, self.encoder_conv_filters, self.encoder_conv_kernel_sizes, self.encoder_conv_strides,\n",
    "                               self.latent_dim)\n",
    "        \n",
    "        # Create decoder\n",
    "        self.decoder = Decoder(self.latent_dim, self.encoder.shape_before_flattening,\n",
    "                               self.decoder_n_layers, self.decoder_conv_t_filters, self.decoder_conv_t_kernel_sizes, self.decoder_conv_t_strides,\n",
    "                               self.output_dim)\n",
    "        \n",
    "        # Create model\n",
    "        self.model_input = self.encoder.input\n",
    "        self.model_output = self.decoder.model(self.encoder.output)\n",
    "\n",
    "        self.model = Model(self.model_input, self.model_output)\n",
    "\n",
    "        # Compile model\n",
    "        self.optimizer = Adam(learning_rate=self.learning_rate)\n",
    "        self.model.compile(optimizer=self.optimizer, loss=MeanSquaredError())\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def plot_model(self, run_folder):\n",
    "        plot_model(self.model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes=True, show_layer_names=True)\n",
    "        plot_model(self.encoder.model, to_file=os.path.join(run_folder ,'viz/encoder.png'), show_shapes=True, show_layer_names=True)\n",
    "        plot_model(self.decoder.model, to_file=os.path.join(run_folder ,'viz/decoder.png'), show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    def load_weights(self, filepath=\"model/weights/params.pkl\"):\n",
    "        self.model.load_weights(filepath)\n",
    "\n",
    "    def fit(self, x, y, batch_size, epochs, validation_split, shuffle, initial_epoch=0, print_every_n_batches=100, lr_decay=1):\n",
    "\n",
    "        # Callbacks\n",
    "        # custom_callback = CustomCallback(\"model\", print_every_n_batches, initial_epoch, self)\n",
    "        lr_sched = step_decay_schedule(initial_lr=self.learning_rate, decay_factor=lr_decay, step_size=1)\n",
    "        # checkpoint2 = ModelCheckpoint(os.path.join(\"model\", 'weights/weights.h5'), save_weights_only = True, verbose=1)\n",
    "\n",
    "        callbacks_list = [lr_sched]\n",
    "\n",
    "        # Training\n",
    "        self.history = self.model.fit(x,\n",
    "                                      y,\n",
    "                                      batch_size=batch_size,\n",
    "                                      epochs=epochs,\n",
    "                                      callbacks=callbacks_list,\n",
    "                                      validation_split=validation_split,\n",
    "                                      shuffle=shuffle,\n",
    "                                      initial_epoch=initial_epoch)\n",
    "        return self.history\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def save(self, folder=\"model\"):\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            os.makedirs(os.path.join(folder, 'viz'))\n",
    "            os.makedirs(os.path.join(folder, 'weights'))\n",
    "            os.makedirs(os.path.join(folder, 'images'))\n",
    "\n",
    "        with open(os.path.join(folder, 'weights/params.pkl'), 'wb') as f:\n",
    "            pickle.dump([self.input_dim,\n",
    "                         self.encoder_conv_filters,\n",
    "                         self.encoder_conv_kernel_sizes,\n",
    "                         self.encoder_conv_strides,\n",
    "                         self.decoder_conv_t_filters,\n",
    "                         self.decoder_conv_t_kernel_sizes,\n",
    "                         self.decoder_conv_t_strides,\n",
    "                         self.latent_dim,\n",
    "                         self.batch_norm,\n",
    "                         self.dropout], f)\n",
    "        self.plot_model(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(input_dim=(28,28,1),\n",
    "                          encoder_n_layers=4,\n",
    "                          encoder_conv_filters=[32,64,64,64],\n",
    "                          encoder_conv_kernel_sizes=[3,3,3,3],\n",
    "                          encoder_conv_strides=[1,2,2,1],\n",
    "                          latent_dim=2,\n",
    "                          decoder_n_layers=4,\n",
    "                          decoder_conv_t_filters=[64,64,32,1],\n",
    "                          decoder_conv_t_kernel_sizes=[3,3,3,3],\n",
    "                          decoder_conv_t_strides=[1,2,2,1],\n",
    "                          output_dim=(28,28,1),\n",
    "                          learning_rate=0.0005,\n",
    "                          batch_norm=False,\n",
    "                          drop_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# for layer in autoencoder.model.layers:\n",
    "#     print(layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist_dataset = mnist.load_data()\n",
    "(trainset, testset) = (mnist_dataset[0], mnist_dataset[1])\n",
    "(X_train, y_train) = trainset\n",
    "(X_test, y_test) = testset\n",
    "\n",
    "# Preprocess data (convert to float and scale to between 0 and 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "\n",
    "# Preprocess data (convert to uint8)\n",
    "# y_train = y_train.astype('uint8')\n",
    "# y_test = y_test.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x=X_train,\n",
    "                y=X_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                validation_split=0.1,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "losses = autoencoder.history.history\n",
    "plt.plot(losses[\"loss\"], label=\"train loss\")\n",
    "plt.plot(losses[\"val_loss\"], label=\"val loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AE reconstructions\n",
    "decoded_images = autoencoder.predict(X_test, batch_size=BATCH_SIZE)\n",
    "n_images = 10\n",
    "for i in range(n_images):\n",
    "    plt.figure(figsize=((5,5)))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(X_test[i], cmap=\"gray\")\n",
    "    plt.title(\"Test Image \" + str(i+1))\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(decoded_images[i].reshape(28, 28), cmap=\"gray\")\n",
    "    plt.title(\"Reconstruction \" + str(i+1))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.load_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the points in the latent space is unknown. For instance, with the mnist dataset and a latent space in 2D, it is possible top plot where each type of digit is located in the latent space.\n",
    "- The plot is not symmetrical about the point (0,0): How should one choose a point in the latent space to produce a specific digit?\n",
    "- Some digits are represented in the latent space over small areas and others over large areas: There will be a lack of diversity in the images produced. (More of the digits with the larger areas).\n",
    "- There are large gaps between digits that contains few individuals: Some generated images (from the gaps) will be porrly formed\n",
    "- The latent space is not continuous: Points in the middle of digits areas can also be ill-formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector_1 = np.random.random(size=(1,2))\n",
    "latent_vector_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_1 = autoencoder.decoder.predict(latent_vector_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_1 = prediction_1.numpy()\n",
    "prediction_1 = prediction_1[0]\n",
    "plt.imshow(prediction_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector_2 = latent_vector_1 + np.array([1, -0.5])\n",
    "latent_vector_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_2 = autoencoder.decoder.predict(latent_vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_2 = prediction_2[0]\n",
    "plt.imshow(prediction_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

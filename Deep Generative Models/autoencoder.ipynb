{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This deep neural networks made of two parts:\n",
    "- An encoder: a network that learns to represent/compress the high-dimensional input data into a lower dimensional latent space\n",
    "- A decoder: a network that learns to decompress a given representation/vector in the latent space to a high-dimensional representation\n",
    "\n",
    "Often used to remove noise from images.\n",
    "\n",
    "It is really easy to create an autoencoder using Keras Model Subclassing API as show in this [Tensorflow tutorial](https://www.tensorflow.org/tutorials/generative/autoencoder).\n",
    "\n",
    "Let's build an autoencoder \"from scratch\" to have a better understanding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand Made Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, Flatten, Dense, Reshape, Conv2DTranspose, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder():\n",
    "\n",
    "    def __init__(self, input_dim, encoder_n_layers, encoder_conv_filters, encoder_conv_kernel_sizes, encoder_conv_strides, latent_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_n_layers = encoder_n_layers\n",
    "        self.encoder_conv_filters = encoder_conv_filters\n",
    "        self.encoder_conv_kernel_sizes = encoder_conv_kernel_sizes\n",
    "        self.encoder_conv_strides = encoder_conv_strides\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        if len(self.encoder_conv_filters) == len(self.encoder_conv_kernel_sizes) == len(self.encoder_conv_strides) == self.encoder_n_layers:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"ERROR\")\n",
    "            return\n",
    "\n",
    "        self.input = Input(shape=self.input_dim, name=\"input\")\n",
    "\n",
    "        x = self.input\n",
    "\n",
    "        for i in range(self.encoder_n_layers):\n",
    "            conv_layer = Conv2D(filters=self.encoder_conv_filters[i],\n",
    "                                kernel_size=self.encoder_conv_kernel_sizes[i],\n",
    "                                strides=self.encoder_conv_strides[i],\n",
    "                                padding=\"same\",\n",
    "                                name=\"encoder_conv_\" + str(i))\n",
    "            x = conv_layer(x)\n",
    "            x = LeakyReLU()(x)\n",
    "\n",
    "        self.shape_before_flattening = tf.keras.backend.int_shape(x)[1:] # See decoder\n",
    "\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        self.output = Dense(self.latent_dim, name=\"output\")(x)\n",
    "\n",
    "        self.model = Model(self.input, self.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim=(28,28,1),\n",
    "                          encoder_n_layers=4,\n",
    "                          encoder_conv_filters=[32,64,64,64],\n",
    "                          encoder_conv_kernel_sizes=[3,3,3,3],\n",
    "                          encoder_conv_strides=[1,2,2,1],\n",
    "                          latent_dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder():\n",
    "\n",
    "    def __init__(self, latent_dim, shape_before_flattening, decoder_n_layers, decoder_conv_t_filters, decoder_conv_t_kernel_sizes, decoder_conv_t_strides, output_dim):\n",
    "        self.output_dim = output_dim\n",
    "        self.shape_before_flattening = shape_before_flattening\n",
    "        self.decoder_n_layers = decoder_n_layers\n",
    "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
    "        self.decoder_conv_t_kernel_sizes = decoder_conv_t_kernel_sizes\n",
    "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        if len(self.decoder_conv_t_filters) == len(self.decoder_conv_t_kernel_sizes) == len(self.decoder_conv_t_strides) == self.decoder_n_layers:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"ERROR\")\n",
    "            return\n",
    "\n",
    "        self.input = Input(shape=(self.latent_dim,), name=\"input\")\n",
    "\n",
    "        x = Dense(np.prod(shape_before_flattening))(self.input) # Connect the input to a dense layer\n",
    "\n",
    "        x = Reshape(self.shape_before_flattening)(x) # Reshape latent space vector for convolutional transpose layers\n",
    "\n",
    "        for i in range(self.decoder_n_layers):\n",
    "            conv_t_layer = Conv2DTranspose(filters=self.decoder_conv_t_filters[i],\n",
    "                                           kernel_size=self.decoder_conv_t_kernel_sizes[i],\n",
    "                                           strides=self.decoder_conv_t_strides[i],\n",
    "                                           padding=\"same\",\n",
    "                                           name=\"decoder_conv_t_\" + str(i))\n",
    "            x = conv_t_layer(x)\n",
    "\n",
    "            if i < self.decoder_n_layers - 1:\n",
    "                x = LeakyReLU()(x)\n",
    "            else:\n",
    "                x = Activation(\"sigmoid\")(x)\n",
    "\n",
    "        self.output = x\n",
    "\n",
    "        self.model = Model(self.input, self.output)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder():\n",
    "\n",
    "    def __init__(self, input_dim,\n",
    "                 encoder_n_layers, encoder_conv_filters, encoder_conv_kernel_sizes, encoder_conv_strides,\n",
    "                 latent_dim,\n",
    "                 decoder_n_layers, decoder_conv_t_filters, decoder_conv_t_kernel_sizes, decoder_conv_t_strides,\n",
    "                 output_dim,\n",
    "                 learning_rate):\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_n_layers = encoder_n_layers\n",
    "        self.encoder_conv_filters = encoder_conv_filters\n",
    "        self.encoder_conv_kernel_sizes = encoder_conv_kernel_sizes\n",
    "        self.encoder_conv_strides = encoder_conv_strides\n",
    "        self.latent_dim = latent_dim\n",
    "        self.decoder_n_layers = decoder_n_layers\n",
    "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
    "        self.decoder_conv_t_kernel_sizes = decoder_conv_t_kernel_sizes\n",
    "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Create encoder\n",
    "        self.encoder = Encoder(self.input_dim,\n",
    "                               self.encoder_n_layers, self.encoder_conv_filters, self.encoder_conv_kernel_sizes, self.encoder_conv_strides,\n",
    "                               self.latent_dim)\n",
    "        \n",
    "        # Create decoder\n",
    "        self.decoder = Decoder(self.latent_dim, self.encoder.shape_before_flattening,\n",
    "                               self.decoder_n_layers, self.decoder_conv_t_filters, self.decoder_conv_t_kernel_sizes, self.decoder_conv_t_strides,\n",
    "                               self.output_dim)\n",
    "        \n",
    "        # Create model\n",
    "        self.model_input = self.encoder.input\n",
    "        self.model_output = self.decoder.model(self.encoder.output)\n",
    "\n",
    "        self.model = Model(self.model_input, self.model_output)\n",
    "\n",
    "        # Compile model\n",
    "        self.optimizer = Adam(learning_rate=self.learning_rate)\n",
    "        \n",
    "        self.model.compile(optimizer=self.optimizer, loss=MeanSquaredError())\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def fit(self, x, y, batch_size, shuffle, epochs, callbacks):\n",
    "        self.model.fit(x, y, batch_size, shuffle, epochs, callbacks)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(input_dim=(28,28,1),\n",
    "                          encoder_n_layers=4,\n",
    "                          encoder_conv_filters=[32,64,64,64],\n",
    "                          encoder_conv_kernel_sizes=[3,3,3,3],\n",
    "                          encoder_conv_strides=[1,2,2,1],\n",
    "                          latent_dim=2,\n",
    "                          decoder_n_layers=4,\n",
    "                          decoder_conv_t_filters=[64,64,32,1],\n",
    "                          decoder_conv_t_kernel_sizes=[3,3,3,3],\n",
    "                          decoder_conv_t_strides=[1,2,2,1],\n",
    "                          output_dim=(28,28,1),\n",
    "                          learning_rate=10**-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " encoder_conv_0 (Conv2D)     (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " leaky_re_lu_279 (LeakyReLU  (None, 28, 28, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " encoder_conv_1 (Conv2D)     (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_280 (LeakyReLU  (None, 14, 14, 64)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " encoder_conv_2 (Conv2D)     (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " leaky_re_lu_281 (LeakyReLU  (None, 7, 7, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " encoder_conv_3 (Conv2D)     (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " leaky_re_lu_282 (LeakyReLU  (None, 7, 7, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 6274      \n",
      "                                                                 \n",
      " model_102 (Functional)      (None, 28, 28, 1)         102017    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200963 (785.01 KB)\n",
      "Trainable params: 200963 (785.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist_dataset = mnist.load_data()\n",
    "(trainset, testset) = (mnist_dataset[0], mnist_dataset[1])\n",
    "(X_train, y_train) = trainset\n",
    "(X_test, y_test) = testset\n",
    "\n",
    "# Preprocess data (convert to float and scale to between 0 and 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "\n",
    "# Preprocess data (convert to uint8)\n",
    "# y_train = y_train.astype('uint8')\n",
    "# y_test = y_test.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 22:58:46.454336: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] remapper failed: INVALID_ARGUMENT: Mutation::Apply error: fanout 'gradient_tape/model_103/leaky_re_lu_282/LeakyRelu/LeakyReluGrad' exist for missing node 'model_103/encoder_conv_3/BiasAdd'.\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x=X_train,\n",
    "                y=y_train,\n",
    "                batch_size=20,\n",
    "                shuffle=True,\n",
    "                epochs=10,\n",
    "                callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction from data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f52e9efd7f0>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANh0lEQVR4nO3df6zddX3H8dfL/sJeYFKwtSuVKqKxOsHlCppuSw3DAYYUo2w0GekSZskGCSxmG2ExkmxxjIiETWdSR2clCFOBQLRzksaNkLHKhZRSKFuRdVh71wvUrUXgtqXv/XG/LJdyz+dezvd7zve07+cjuTnnfN/ne77vfHtf/X7v+XzP+TgiBODY95a2GwDQH4QdSIKwA0kQdiAJwg4kMbufG5vreXGchvq5SSCVV/QLHYhxT1WrFXbb50u6RdIsSX8XETeUnn+chnSOz62zSQAFm2NTx1rXp/G2Z0n6qqQLJC2XtNr28m5fD0Bv1fmb/WxJT0fEMxFxQNKdklY10xaAptUJ+xJJP530eFe17HVsr7U9YnvkoMZrbA5AHXXCPtWbAG+49jYi1kXEcEQMz9G8GpsDUEedsO+StHTS41Ml7a7XDoBeqRP2hyWdYftdtudKulTSfc20BaBpXQ+9RcQh21dJ+idNDL2tj4gnGusMQKNqjbNHxEZJGxvqBUAPcbkskARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIlaUzbb3ilpv6RXJR2KiOEmmgLQvFphr3w8Ip5v4HUA9BCn8UASdcMekn5o+xHba6d6gu21tkdsjxzUeM3NAehW3dP4FRGx2/ZCSffbfioiHpj8hIhYJ2mdJJ3oBVFzewC6VOvIHhG7q9sxSfdIOruJpgA0r+uw2x6yfcJr9yV9QtK2phoD0Kw6p/GLJN1j+7XX+VZE/KCRrgA0ruuwR8Qzks5ssBcAPcTQG5AEYQeSIOxAEoQdSIKwA0k08UGYFF747Mc61t552dPFdZ8aW1SsHxifU6wvuaNcn7/rxY61w1ueLK6LPDiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLPP0J/88bc61j499PPyyqfX3PjKcnnnoZc61m557uM1N370+vHYaR1rQzf9UnHd2Zseabqd1nFkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkHNG/SVpO9II4x+f2bXtN+sVnzulYe/5D5f8zT9pe3sc/f7+L9bkf+p9i/cYP3t2xdt5bXy6u+/2Xji/WPzm/82fl63o5DhTrm8eHivWVxx3setvv+f4Vxfp71z7c9Wu3aXNs0r7YO+UvFEd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCz7PP0NB3Nxdq9V77xHqr62/esbJj7S9WLCtv+1/K33l/48r3dNHRzMx++XCxPrR1tFg/+YG7ivVfmdv5+/bn7yx/F/+xaNoju+31tsdsb5u0bIHt+23vqG5P6m2bAOqayWn8NySdf8SyayVtiogzJG2qHgMYYNOGPSIekLT3iMWrJG2o7m+QdHGzbQFoWrdv0C2KiFFJqm4Xdnqi7bW2R2yPHNR4l5sDUFfP342PiHURMRwRw3M0r9ebA9BBt2HfY3uxJFW3Y821BKAXug37fZLWVPfXSLq3mXYA9Mq04+y279DEN5efYnuXpC9IukHSt21fLulZSZf0skmUHfrvPR1rQ3d1rknSq9O89tB3X+iio2bs+f2PFesfmFv+9f3S3vd1rC37+2eK6x4qVo9O04Y9IlZ3KB2d30IBJMXlskAShB1IgrADSRB2IAnCDiTBR1zRmtmnLS3Wv3LdV4r1OZ5VrH/nlt/sWDt59KHiuscijuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7GjNU3+0pFj/yLzyVNZPHChPR73gyZfedE/HMo7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+zoqfFPfqRj7dHP3DzN2uUZhP7g6quL9bf+64+nef1cOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs6Onnr2g8/HkeJfH0Vf/53nF+vwfPFasR7Gaz7RHdtvrbY/Z3jZp2fW2f2Z7S/VzYW/bBFDXTE7jvyHp/CmW3xwRZ1U/G5ttC0DTpg17RDwgaW8fegHQQ3XeoLvK9tbqNP+kTk+yvdb2iO2RgxqvsTkAdXQb9q9JOl3SWZJGJd3U6YkRsS4ihiNieM40H2wA0DtdhT0i9kTEqxFxWNLXJZ3dbFsAmtZV2G0vnvTwU5K2dXougMEw7Ti77TskrZR0iu1dkr4gaaXtszQxlLlT0hW9axGD7C0nnFCsX/brD3as7Tv8SnHdsS++u1ifN/5wsY7XmzbsEbF6isW39qAXAD3E5bJAEoQdSIKwA0kQdiAJwg4kwUdcUcuO6z9QrH/vlL/tWFu149PFdedtZGitSRzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlR9L+/+9Fifevv/HWx/pNDBzvWXvyrU4vrztNosY43hyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHtys5f8crF+zef/oVif5/Kv0KWPXdax9vZ/5PPq/cSRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJz9GOfZ5X/iM7+3q1i/5PgXivXb9y8s1hd9vvPx5HBxTTRt2iO77aW2f2R7u+0nbF9dLV9g+37bO6rbk3rfLoBuzeQ0/pCkz0XE+yV9VNKVtpdLulbSpog4Q9Km6jGAATVt2CNiNCIere7vl7Rd0hJJqyRtqJ62QdLFPeoRQAPe1Bt0tpdJ+rCkzZIWRcSoNPEfgqQp/3izvdb2iO2Rgxqv2S6Abs047LaPl3SXpGsiYt9M14uIdRExHBHDczSvmx4BNGBGYbc9RxNBvz0i7q4W77G9uKovljTWmxYBNGHaoTfblnSrpO0R8eVJpfskrZF0Q3V7b086RD1nvq9Y/vOFt9V6+a9+8ZJi/W2PPVTr9dGcmYyzr5B0maTHbW+pll2niZB/2/blkp6VVP5XB9CqacMeEQ9Kcofyuc22A6BXuFwWSIKwA0kQdiAJwg4kQdiBJPiI6zFg1vL3dqytvbPe5Q/L119ZrC+77d9qvT76hyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPsx4Kk/7PzFvhfNn/GXCk3p1H8+UH5CRK3XR/9wZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnPwq8ctHZxfqmi24qVOc32wyOWhzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJmczPvlTSNyW9Q9JhSesi4hbb10v6rKTnqqdeFxEbe9VoZrtXzCrW3zm7+7H02/cvLNbn7Ct/np1Psx89ZnJRzSFJn4uIR22fIOkR2/dXtZsj4ku9aw9AU2YyP/uopNHq/n7b2yUt6XVjAJr1pv5mt71M0oclba4WXWV7q+31tqf8biTba22P2B45qPF63QLo2ozDbvt4SXdJuiYi9kn6mqTTJZ2liSP/lBdoR8S6iBiOiOE5mle/YwBdmVHYbc/RRNBvj4i7JSki9kTEqxFxWNLXJZU/rQGgVdOG3bYl3Sppe0R8edLyxZOe9ilJ25pvD0BTZvJu/ApJl0l63PaWatl1klbbPksToy87JV3Rg/5Q01++sLxYf+i3lhXrMfp4g92gTTN5N/5BSZ6ixJg6cBThCjogCcIOJEHYgSQIO5AEYQeSIOxAEo4+Trl7ohfEOT63b9sDstkcm7Qv9k41VM6RHciCsANJEHYgCcIOJEHYgSQIO5AEYQeS6Os4u+3nJP3XpEWnSHq+bw28OYPa26D2JdFbt5rs7bSIePtUhb6G/Q0bt0ciYri1BgoGtbdB7Uuit271qzdO44EkCDuQRNthX9fy9ksGtbdB7Uuit271pbdW/2YH0D9tH9kB9AlhB5JoJey2z7f977aftn1tGz10Ynun7cdtb7E90nIv622P2d42adkC2/fb3lHdTjnHXku9XW/7Z9W+22L7wpZ6W2r7R7a3237C9tXV8lb3XaGvvuy3vv/NbnuWpP+QdJ6kXZIelrQ6Ip7sayMd2N4paTgiWr8Aw/ZvSHpR0jcj4oPVshsl7Y2IG6r/KE+KiD8dkN6ul/Ri29N4V7MVLZ48zbikiyX9nlrcd4W+flt92G9tHNnPlvR0RDwTEQck3SlpVQt9DLyIeEDS3iMWr5K0obq/QRO/LH3XobeBEBGjEfFodX+/pNemGW913xX66os2wr5E0k8nPd6lwZrvPST90PYjtte23cwUFkXEqDTxyyNpYcv9HGnaabz76Yhpxgdm33Uz/XldbYR9qu/HGqTxvxUR8auSLpB0ZXW6ipmZ0TTe/TLFNOMDodvpz+tqI+y7JC2d9PhUSbtb6GNKEbG7uh2TdI8GbyrqPa/NoFvdjrXcz/8bpGm8p5pmXAOw79qc/ryNsD8s6Qzb77I9V9Klku5roY83sD1UvXEi20OSPqHBm4r6PklrqvtrJN3bYi+vMyjTeHeaZlwt77vWpz+PiL7/SLpQE+/I/0TSn7XRQ4e+3i3psernibZ7k3SHJk7rDmrijOhySSdL2iRpR3W7YIB6u03S45K2aiJYi1vq7dc08afhVklbqp8L2953hb76st+4XBZIgivogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJ/wNGNvRI2D7VDgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f52e9ec5dc0>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67792575, 0.34272522]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_vector_1 = np.random.random(size=(1,2))\n",
    "latent_vector_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 219ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_1 = autoencoder.decoder.predict(latent_vector_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f52e9e5bac0>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction_1 = prediction_1.numpy()\n",
    "prediction_1 = prediction_1[0]\n",
    "plt.imshow(prediction_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
